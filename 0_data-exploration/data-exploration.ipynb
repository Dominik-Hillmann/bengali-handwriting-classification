{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Handwritten Grapheme Classification\n",
    "This is a contest for optical character recognition for the written Bengali language spoken by about 200 million people. Most of these people live in Bangladesh and India. Bengali consists of 49 letters (11 vowels, 38 consonants) which can have 18 accents. This multiplies to about 13 000 possible letters to be identified by a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Header image](https://upload.wikimedia.org/wikipedia/commons/0/05/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE_%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A6%B8%E0%A6%AE%E0%A7%82%E0%A6%B9.svg)\n",
    "<a href=\"https://commons.wikimedia.org/wiki/File:%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE_%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A6%B8%E0%A6%AE%E0%A7%82%E0%A6%B9.svg\" title=\"via Wikimedia Commons\">Nirvik12</a> [<a href=\"https://creativecommons.org/licenses/by-sa/4.0\">CC BY-SA</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This is why the recognition challenge is split up into three smaller challenges:\n",
    "1. Identify the base letter (*grapheme root*)\n",
    "2. Identify the accent of the vowel (*vowel diacritic*) or\n",
    "3. Identify the accent of the consonant (*consonant diacritic*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files\n",
    "* `class_map.csv`: 3 columns\n",
    "    * `Component_type` which are either the base letter or consonant accent or vowel accent\n",
    "    * `Label` the component label\n",
    "    * `Component` visual representation of the component\n",
    "* `train.csv`: contains meta information about the actual pictures\n",
    "    * `Image_Id` the key for the pictures contained in the `.parquet` files\n",
    "    * `Grapheme_root` the label of the base letter of this character\n",
    "    * `Vowel_diacritic` the label of the vowel accent\n",
    "    * `Consonant_diacritic` the label of the consonant diacritic\n",
    "    * `Graphme` the complete letter for illustration purposes\n",
    "    * **verify**: label 0 means that there is no accent because, for example, a vowel base letter cannot have a consonant accent. This means a classification into vowel and consonant beforehand might be useful\n",
    "* `test.csv`: every image will require three predictions\n",
    "    * `Row_Id` key to the sample submission\n",
    "    * `Image_Id` key to the `.parquet` file\n",
    "    * `Component` the component to be predicted\n",
    "* `sample_submission.csv`: the example\n",
    "    * `Row_Id` the submission key concatenated with the required diacritic\n",
    "    * `Target` the predicted label for the target type\n",
    "* `.parquet` files: contain the actual pixel data\n",
    "    * Four files for each train and test data\n",
    "    * *Going to find out more now...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data `.parquet` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import os\n",
    "# External libraries\n",
    "import pandas as pd\n",
    "# Self-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_image_data_0.parquet', 'train_image_data_1.parquet', 'train_image_data_2.parquet', 'train_image_data_3.parquet']\n",
      "['test_image_data_0.parquet', 'test_image_data_1.parquet', 'test_image_data_2.parquet', 'test_image_data_3.parquet']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('..', 'data', 'bengaliai-cv19')\n",
    "data_files = os.listdir(data_path)\n",
    "train_files = [f for f in data_files if 'parquet' in f and 'train' in f]\n",
    "test_files = [f for f in data_files if 'parquet' in f and 'test' in f]\n",
    "print(train_files)\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data files:\n",
      "Shape: (50210, 32333)\n",
      "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
      "0  Train_0  254  253  252  253  251  252  253  251  251  ...    253    253   \n",
      "1  Train_1  251  244  238  245  248  246  246  247  251  ...    255    255   \n",
      "2  Train_2  251  250  249  250  249  245  247  252  252  ...    254    253   \n",
      "\n",
      "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    253    253    253    253    253    253    253    251  \n",
      "1    255    255    255    255    255    255    255    254  \n",
      "2    252    252    253    253    253    253    251    249  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (50210, 32333)\n",
      "      image_id    0    1    2    3    4    5    6    7    8  ...  32322  \\\n",
      "0  Train_50210  246  253  251  250  249  252  246  250  250  ...    255   \n",
      "1  Train_50211  250  245  241  244  249  253  253  254  254  ...    254   \n",
      "2  Train_50212  248  248  249  249  250  251  250  250  249  ...    255   \n",
      "\n",
      "   32323  32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    255    255    255    255    255    255    255    254    253  \n",
      "1    254    253    253    253    254    255    253    253    254  \n",
      "2    255    255    255    255    255    255    255    255    255  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (50210, 32333)\n",
      "       image_id    0    1    2    3    4    5    6    7    8  ...  32322  \\\n",
      "0  Train_100420  247  246  249  250  249  250  253  253  252  ...    255   \n",
      "1  Train_100421  247  249  251  252  252  249  250  252  249  ...    254   \n",
      "2  Train_100422  241  224  227  227  226  223  219  231  236  ...    252   \n",
      "\n",
      "   32323  32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    254    254    255    255    255    254    253    252    254  \n",
      "1    253    253    253    253    253    253    253    253    253  \n",
      "2    251    251    247    247    251    252    251    249    250  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (50210, 32333)\n",
      "       image_id    0    1    2    3    4    5    6    7    8  ...  32322  \\\n",
      "0  Train_150630  246  245  244  244  245  247  246  244  247  ...    252   \n",
      "1  Train_150631  213  241  247  247  246  247  246  244  247  ...    193   \n",
      "2  Train_150632  253  253  252  252  251  252  253  253  253  ...    253   \n",
      "\n",
      "   32323  32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    252    251    251    251    251    251    252    253    252  \n",
      "1    198    200    202    200    196    194    192    175    117  \n",
      "2    253    253    253    253    253    253    253    253    253  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Test data files:\n",
      "Shape: (3, 32333)\n",
      "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
      "0   Test_0  247  253  253  252  252  252  252  253  253  ...    254    254   \n",
      "1   Test_1  253  253  253  253  253  253  253  253  253  ...    255    255   \n",
      "2   Test_2  253  253  253  253  253  252  251  252  252  ...    255    255   \n",
      "\n",
      "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    254    254    254    254    253    253    252    250  \n",
      "1    255    255    255    255    255    255    255    255  \n",
      "2    255    255    255    255    255    254    253    252  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (3, 32333)\n",
      "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
      "0   Test_3  199  227  236  241  238  242  245  243  243  ...    222    222   \n",
      "1   Test_4  243  246  251  252  251  249  250  250  251  ...    251    252   \n",
      "2   Test_5  251  250  250  251  252  254  252  251  251  ...    253    253   \n",
      "\n",
      "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    226    224    222    227    220    208    194    136  \n",
      "1    252    252    252    253    253    253    253    253  \n",
      "2    252    252    252    253    252    249    248    249  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (3, 32333)\n",
      "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
      "0   Test_6  250  252  252  253  254  255  255  255  255  ...    255    255   \n",
      "1   Test_7  254  254  254  254  254  255  255  255  255  ...    255    255   \n",
      "2   Test_8  251  251  249  247  247  248  249  249  249  ...    252    252   \n",
      "\n",
      "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    255    255    255    255    255    255    255    255  \n",
      "1    255    255    255    255    255    254    252    251  \n",
      "2    252    252    252    252    252    250    250    250  \n",
      "\n",
      "[3 rows x 32333 columns]\n",
      "Shape: (3, 32333)\n",
      "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
      "0   Test_9  250  251  249  248  248  249  248  249  252  ...    254    254   \n",
      "1  Test_10  245  246  248  249  250  248  247  250  252  ...    252    252   \n",
      "2  Test_11  252  252  252  252  252  252  252  252  252  ...    253    253   \n",
      "\n",
      "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
      "0    253    252    252    253    254    253    253    253  \n",
      "1    252    253    254    254    254    254    254    254  \n",
      "2    253    253    253    253    253    253    253    252  \n",
      "\n",
      "[3 rows x 32333 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Training data files:')\n",
    "for file in train_files:\n",
    "    train_data = pd.read_parquet(os.path.join(data_path, file))\n",
    "    print('Shape:', train_data.shape)\n",
    "    print(train_data.head(3))\n",
    "    del train_data\n",
    "    \n",
    "print('Test data files:')\n",
    "for file in test_files:\n",
    "    test_data = pd.read_parquet(os.path.join(data_path, file))\n",
    "    print('Shape:', test_data.shape)\n",
    "    print(test_data.head(3))\n",
    "    del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rows represent images, all the columns but the first are pixel values\n",
    "    * First column: The ID of the image such that it can be found in the `train.csv`\n",
    "* Pixel values range from 0 to 255\n",
    "* In both train and test sets, there are 32332 values, which represent the 137 $*$ 236 pixels of each picture, whether row by row or column by column will be found out by reconstructing a few images\n",
    "* Each training batch contains 50210 images, they are continously numbered throughout the four files\n",
    "    * We have 200840 training images\n",
    "* Each test batch contains three images\n",
    "    * We have 12 test images, for each we have to make predictions for all three targets, meaning we have to make 36 predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
